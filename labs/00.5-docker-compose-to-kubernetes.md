# Lab 0.5: Docker Compose ‚Üí Kubernetes Migration üê≥ ‚û°Ô∏è ‚ò∏Ô∏è

**‚è± Time**: 40 minutes  
**üéØ Difficulty**: ‚≠ê‚≠ê Intermediate  
**üìã Prerequisites**: Docker Compose experience + Lab 0 complete

---

## üéØ Objective

**The Problem**: You've been shipping apps with `docker-compose up` for months. Now your company wants to move to Kubernetes, and you're staring at 200-line YAML files wondering, *"Where's my docker-compose.yml?"*

**This Lab**: Side-by-side translation of Docker Compose concepts to Kubernetes. By the end, you'll convert a 3-tier app (frontend + backend + database) from `docker-compose.yml` to K8s manifests.

**What You'll Learn**:
- Docker Compose ‚Üí Kubernetes concept mapping (services, volumes, networks, env vars)
- Why Kubernetes manifests are more verbose (spoiler: explicit control = production safety)
- Conversion patterns for common scenarios (port mappings, healthchecks, restart policies)
- When to keep Docker Compose (local dev) vs. move to Kubernetes (production)

---

## üìö Concept Map: Docker Compose ‚Üî Kubernetes

| Docker Compose Feature | Kubernetes Equivalent | Why Different? |
|------------------------|----------------------|----------------|
| `services:` | `Deployment` + `Service` | K8s separates compute (pods) from networking (services) |
| `image:` | `spec.template.spec.containers[].image` | Same image, but nested in pod spec |
| `ports:` | `Service` with `type: LoadBalancer/NodePort` | Compose maps ports directly; K8s needs explicit service |
| `environment:` | `ConfigMap` + `env` OR `Secret` | K8s recommends separating config from deployment |
| `volumes:` | `PersistentVolumeClaim` + `volumeMounts` | Compose uses bind mounts; K8s provisions storage |
| `depends_on:` | Init containers OR readiness probes | K8s doesn't support startup order (by design - see below) |
| `restart: always` | `restartPolicy: Always` (default) | Same concept, different YAML |
| `networks:` | Namespace + `NetworkPolicy` | K8s networking is flat by default (all pods can talk) |
| `healthcheck:` | `livenessProbe` + `readinessProbe` | K8s has 2 types: restart vs. traffic control |

**Key Insight**: Docker Compose optimizes for **developer convenience** (one file, implicit defaults). Kubernetes optimizes for **production resilience** (explicit control, separation of concerns).

---

## üî¨ Hands-On: Side-by-Side Conversion

We'll convert the **E-commerce app** from Lab 2. Here's the original `docker-compose.yml`:

```yaml
# docker-compose.yml (Docker Compose version)
version: '3.8'

services:
  postgres:
    image: postgres:13
    environment:
      POSTGRES_USER: ecomuser
      POSTGRES_PASSWORD: password123
      POSTGRES_DB: ecomdb
    volumes:
      - postgres-data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ecomuser"]
      interval: 10s
      timeout: 5s
      retries: 5

  backend:
    image: temitayocharles/ecommerce-backend:latest
    environment:
      DATABASE_URL: postgres://ecomuser:password123@postgres:5432/ecomdb
      PORT: 3001
    depends_on:
      postgres:
        condition: service_healthy
    ports:
      - "3001:3001"

  frontend:
    image: temitayocharles/ecommerce-frontend:latest
    environment:
      REACT_APP_API_URL: http://backend:3001
    depends_on:
      - backend
    ports:
      - "3000:3000"

volumes:
  postgres-data:
```

**What This Does**:
1. Starts Postgres with persistent storage
2. Waits for Postgres to be healthy, then starts backend
3. Starts frontend after backend is ready
4. Maps ports to localhost (5432, 3001, 3000)

**To Run**: `docker-compose up` (1 command, ~15 seconds)

---

### üîÄ Kubernetes Conversion (Step-by-Step)

#### 1Ô∏è‚É£ **Database (Postgres)** ‚Üí StatefulSet + Service + PVC

**Docker Compose**:
```yaml
services:
  postgres:
    image: postgres:13
    volumes:
      - postgres-data:/var/lib/postgresql/data
    environment:
      POSTGRES_PASSWORD: password123
```

**Kubernetes** (3 separate manifests):

```yaml
# postgres-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: postgres   # Links to headless service
  replicas: 1
  selector:
    matchLabels:
      app: postgres
  template:
    metadata:
      labels:
        app: postgres
    spec:
      containers:
      - name: postgres
        image: postgres:13
        env:
        - name: POSTGRES_PASSWORD
          valueFrom:
            secretKeyRef:          # Security: Use Secret, not plain ConfigMap
              name: postgres-secret
              key: password
        - name: POSTGRES_USER
          value: ecomuser
        - name: POSTGRES_DB
          value: ecomdb
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 5Gi

---
# postgres-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: postgres
spec:
  clusterIP: None      # Headless service (for StatefulSet DNS)
  selector:
    app: postgres
  ports:
  - port: 5432
    targetPort: 5432

---
# postgres-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: postgres-secret
type: Opaque
stringData:
  password: password123
```

**Why More Verbose?**
- **StatefulSet vs. Deployment**: Guarantees stable pod identity (`postgres-0`)
- **Headless service**: Enables DNS like `postgres-0.postgres.default.svc.cluster.local`
- **volumeClaimTemplates**: Auto-creates PVC per replica (for horizontal scaling)
- **Secret**: Production best practice (not hardcoded in env)

---

#### 2Ô∏è‚É£ **Backend API** ‚Üí Deployment + Service + ConfigMap

**Docker Compose**:
```yaml
services:
  backend:
    image: temitayocharles/ecommerce-backend:latest
    environment:
      DATABASE_URL: postgres://ecomuser:password123@postgres:5432/ecomdb
    depends_on:
      postgres:
        condition: service_healthy
```

**Kubernetes**:

```yaml
# backend-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: backend-config
data:
  DATABASE_HOST: postgres
  DATABASE_PORT: "5432"
  DATABASE_NAME: ecomdb
  DATABASE_USER: ecomuser

---
# backend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: backend
spec:
  replicas: 2                    # Easy horizontal scaling (Compose can't do this)
  selector:
    matchLabels:
      app: backend
  template:
    metadata:
      labels:
        app: backend
    spec:
      containers:
      - name: backend
        image: temitayocharles/ecommerce-backend:latest
        env:
        - name: DATABASE_HOST
          valueFrom:
            configMapKeyRef:
              name: backend-config
              key: DATABASE_HOST
        - name: DATABASE_PASSWORD
          valueFrom:
            secretKeyRef:
              name: postgres-secret
              key: password
        # ... (other env vars from ConfigMap)
        ports:
        - containerPort: 3001
        livenessProbe:             # Better than Compose healthcheck (restart on failure)
          httpGet:
            path: /health
            port: 3001
          initialDelaySeconds: 15
          periodSeconds: 10
        readinessProbe:            # Traffic control (Compose doesn't have this)
          httpGet:
            path: /ready
            port: 3001
          initialDelaySeconds: 5
          periodSeconds: 5

---
# backend-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: backend
spec:
  selector:
    app: backend
  ports:
  - port: 3001
    targetPort: 3001
  type: ClusterIP               # Internal only (no external port mapping)
```

**Key Differences**:
- **No `depends_on`**: Kubernetes doesn't guarantee startup order. Solution:
  - Backend has retry logic (connects to Postgres when it's ready)
  - Readiness probe ensures backend doesn't receive traffic until DB is reachable
- **Liveness vs. Readiness**: Two separate probes for restart vs. traffic control
- **ConfigMap**: Separates config from deployment (change config without rebuilding image)
- **Replicas**: Easy to scale to 5 replicas (Compose can't do multi-replica by default)

---

#### 3Ô∏è‚É£ **Frontend (React)** ‚Üí Deployment + Service

**Docker Compose**:
```yaml
services:
  frontend:
    image: temitayocharles/ecommerce-frontend:latest
    environment:
      REACT_APP_API_URL: http://backend:3001
    ports:
      - "3000:3000"
```

**Kubernetes**:

```yaml
# frontend-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: frontend
  template:
    metadata:
      labels:
        app: frontend
    spec:
      containers:
      - name: frontend
        image: temitayocharles/ecommerce-frontend:latest
        env:
        - name: REACT_APP_API_URL
          value: http://backend:3001    # Service name works (Compose compat!)
        ports:
        - containerPort: 3000

---
# frontend-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: frontend
spec:
  selector:
    app: frontend
  ports:
  - port: 80
    targetPort: 3000
  type: LoadBalancer              # Exposes to outside world (like Compose ports)
```

**Why Simpler?**
- Frontend is stateless (no volume needed)
- No database connection (no complex probes)
- `type: LoadBalancer` maps to external IP (like Compose `ports:` but production-ready)

---

## üöÄ Deploy & Compare

### Docker Compose Deployment
```bash
# Start all services
docker-compose up -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f

# Stop everything
docker-compose down
```

**Total commands**: 1 to start, 1 to stop  
**Files**: 1 (`docker-compose.yml`)  
**Time to running**: ~15 seconds

---

### Kubernetes Deployment
```bash
# Create namespace
kubectl create namespace ecommerce-k8s

# Apply all manifests
kubectl apply -f postgres-secret.yaml -n ecommerce-k8s
kubectl apply -f postgres-statefulset.yaml -n ecommerce-k8s
kubectl apply -f postgres-service.yaml -n ecommerce-k8s
kubectl apply -f backend-configmap.yaml -n ecommerce-k8s
kubectl apply -f backend-deployment.yaml -n ecommerce-k8s
kubectl apply -f backend-service.yaml -n ecommerce-k8s
kubectl apply -f frontend-deployment.yaml -n ecommerce-k8s
kubectl apply -f frontend-service.yaml -n ecommerce-k8s

# Check status
kubectl get all -n ecommerce-k8s

# View logs
kubectl logs -n ecommerce-k8s -l app=backend --tail=50

# Stop everything
kubectl delete namespace ecommerce-k8s
```

**Total commands**: 8 applies OR `kubectl apply -f k8s/` (if files in folder)  
**Files**: 8 manifests  
**Time to running**: ~60 seconds (volume provisioning + image pulls)

---

## üìä When to Use Docker Compose vs. Kubernetes

| Scenario | Use Docker Compose | Use Kubernetes |
|----------|-------------------|----------------|
| **Local development** | ‚úÖ (fast, simple) | ‚ùå (overkill) |
| **Quick prototyping** | ‚úÖ | ‚ùå |
| **CI/CD integration tests** | ‚úÖ (spin up deps) | ‚ö†Ô∏è (if already on K8s) |
| **Production deployment** | ‚ùå (no HA, scaling) | ‚úÖ |
| **Multi-environment (dev/staging/prod)** | ‚ùå (no namespaces) | ‚úÖ |
| **Auto-scaling** | ‚ùå (manual only) | ‚úÖ (HPA) |
| **Self-healing** | ‚ö†Ô∏è (restart only) | ‚úÖ (recreate on node failure) |
| **Rolling updates** | ‚ùå (downtime) | ‚úÖ (zero-downtime) |
| **Secrets management** | ‚ùå (plaintext) | ‚úÖ (encrypted at rest) |
| **Network policies** | ‚ùå | ‚úÖ |

**Golden Rule**: Use **Docker Compose for local dev**, **Kubernetes for production**. Many teams use both:
- Developers run `docker-compose up` locally (fast feedback)
- CI/CD deploys same images to Kubernetes (production parity)

---

## üõ†Ô∏è Conversion Patterns Cheat Sheet

### Pattern 1: Port Mappings
**Compose**: `ports: - "8080:80"` (maps to localhost:8080)  
**K8s**: `Service` with `type: LoadBalancer` (maps to external IP)

```yaml
# Docker Compose
ports:
  - "8080:80"

# Kubernetes
apiVersion: v1
kind: Service
spec:
  type: LoadBalancer
  ports:
  - port: 8080
    targetPort: 80
```

---

### Pattern 2: Environment Variables
**Compose**: Inline in `environment:`  
**K8s**: Use `ConfigMap` for non-sensitive, `Secret` for passwords

```yaml
# Docker Compose
environment:
  DATABASE_URL: postgres://user:pass@db:5432/mydb

# Kubernetes (split into ConfigMap + Secret)
apiVersion: v1
kind: ConfigMap
data:
  DATABASE_HOST: db
  DATABASE_PORT: "5432"
---
apiVersion: v1
kind: Secret
stringData:
  DATABASE_PASSWORD: pass
---
# In Deployment
env:
- name: DATABASE_HOST
  valueFrom:
    configMapKeyRef: ...
- name: DATABASE_PASSWORD
  valueFrom:
    secretKeyRef: ...
```

---

### Pattern 3: Volumes (Persistent Data)
**Compose**: Named volume `- db-data:/var/lib/mysql`  
**K8s**: PVC + volumeMounts

```yaml
# Docker Compose
volumes:
  - db-data:/var/lib/mysql

# Kubernetes
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: db-data
spec:
  accessModes: ["ReadWriteOnce"]
  resources:
    requests:
      storage: 10Gi
---
# In Deployment
volumeMounts:
- name: db-data
  mountPath: /var/lib/mysql
volumes:
- name: db-data
  persistentVolumeClaim:
    claimName: db-data
```

---

### Pattern 4: Healthchecks
**Compose**: `healthcheck:` with shell command  
**K8s**: `livenessProbe` (restart) + `readinessProbe` (traffic)

```yaml
# Docker Compose
healthcheck:
  test: ["CMD", "curl", "-f", "http://localhost/health"]
  interval: 30s
  timeout: 10s
  retries: 3

# Kubernetes (more granular control)
livenessProbe:
  httpGet:
    path: /health
    port: 8080
  initialDelaySeconds: 30
  periodSeconds: 10
readinessProbe:
  httpGet:
    path: /ready
    port: 8080
  initialDelaySeconds: 5
  periodSeconds: 5
```

---

### Pattern 5: Restart Policies
**Compose**: `restart: always|on-failure|unless-stopped`  
**K8s**: `restartPolicy: Always|OnFailure|Never` (pod-level)

```yaml
# Docker Compose
restart: on-failure

# Kubernetes (in Pod spec)
spec:
  restartPolicy: OnFailure
```

---

### Pattern 6: Dependencies (`depends_on`)
**Compose**: Explicit startup order  
**K8s**: No native support (use init containers or app retry logic)

```yaml
# Docker Compose
depends_on:
  - db

# Kubernetes Option 1: Init container (wait for DB)
initContainers:
- name: wait-for-db
  image: busybox
  command: ['sh', '-c', 'until nc -z db 5432; do sleep 1; done']

# Kubernetes Option 2: Application-level retry (recommended)
# Backend code:
# while (true) {
#   try { connectToDatabase(); break; }
#   catch { sleep(1); }
# }
```

**Why K8s Avoids Startup Order**:
- In production, services restart independently (DB might restart while app is running)
- Apps must handle "DB not ready" at any time (not just startup)
- Init containers work, but retry logic is more resilient

---

## üéØ Conversion Challenge: Convert Your Own App!

**Task**: Take a `docker-compose.yml` from your own project and convert it to Kubernetes manifests.

**Step-by-Step**:
1. **List services**: Count how many containers (each becomes a Deployment or StatefulSet)
2. **Identify stateful services**: Does it use volumes? ‚Üí Use StatefulSet + PVC
3. **Extract secrets**: Move passwords to `Secret` manifests
4. **Extract config**: Move non-sensitive env vars to `ConfigMap`
5. **Create Services**: Each service needs a K8s `Service` for DNS (even if not external)
6. **Add probes**: Replace `healthcheck` with `livenessProbe` + `readinessProbe`
7. **Remove `depends_on`**: Add retry logic in app code OR use init containers
8. **Test**: Deploy to local K8s (Docker Desktop / Rancher Desktop), verify with `kubectl get all`

**Example Services to Try**:
- **WordPress + MySQL**: StatefulSet (MySQL) + Deployment (WordPress) + PVCs
- **Microservices**: Multiple Deployments + Services + Ingress for routing
- **Cron jobs**: Use `CronJob` kind (Compose doesn't have this!)

---

## üß™ Validation Checklist

After conversion, verify:
- [ ] All pods show `Running` status: `kubectl get pods -n <namespace>`
- [ ] Services have endpoints: `kubectl get endpoints -n <namespace>`
- [ ] PVCs are `Bound`: `kubectl get pvc -n <namespace>`
- [ ] App responds: `kubectl port-forward svc/<service> 8080:80` ‚Üí visit http://localhost:8080
- [ ] Logs show no connection errors: `kubectl logs -n <namespace> -l app=<name>`
- [ ] Health endpoints work: `kubectl exec <pod> -- curl localhost/health`

---

## üîë Key Takeaways

1. **Docker Compose is faster for local dev** (1 file, 1 command, 15 seconds)
2. **Kubernetes is production-grade** (HA, scaling, secrets, zero-downtime updates)
3. **K8s requires more YAML** (but it's explicit control, not complexity)
4. **Use both**: Compose for dev, K8s for prod (same images, different orchestration)
5. **No `depends_on` in K8s**: Apps must retry connections (production reality)
6. **Secrets matter**: K8s enforces separation (ConfigMap vs. Secret)
7. **Probes are critical**: liveness (restart) + readiness (traffic) > Compose healthcheck

---

## üìö What's Next?

Now that you understand the mapping, dive into Kubernetes-specific features that Compose can't do:
- **[Lab 1: Weather Basics](01-weather-basics.md)** ‚Üí Deploy your first K8s app (no Compose)
- **[Lab 7: Social Scaling](07-social-scaling.md)** ‚Üí HPA (auto-scaling pods based on CPU)
- **[Lab 9: Chaos Engineering](09-chaos.md)** ‚Üí Self-healing (delete pods, watch K8s recreate them)
- **[Lab 10: Helm](10-helm-package-management.md)** ‚Üí Package K8s apps like `npm`/`apt`

**Pro Tip**: Keep your `docker-compose.yml` for local dev! Many teams use:
- `docker-compose up` for fast local iteration
- `kubectl apply -f k8s/` for staging/production
- Same container images for both (development/production parity)

---

## üßπ Cleanup

```bash
# If you deployed the example app
kubectl delete namespace ecommerce-k8s
```

---

## ü§î Common Questions

**Q: Why doesn't K8s have a `docker-compose.yml` equivalent?**  
A: Because production needs are different. Compose optimizes for simplicity (single-host, dev environments). K8s optimizes for resilience (multi-host, auto-healing, rolling updates). The extra YAML buys you production features.

**Q: Can I auto-convert Compose to K8s?**  
A: Tools exist (`kompose`), but they generate basic manifests. You'll need to add probes, resource limits, security contexts, etc. manually. Better to learn the patterns.

**Q: Should I use Docker Compose in production?**  
A: Only for single-host, low-traffic apps. For anything user-facing or business-critical, use K8s (or managed alternatives like AWS ECS, Cloud Run, etc.).

**Q: What about Docker Swarm?**  
A: Swarm is simpler than K8s but less feature-rich. Kubernetes won the orchestration war (95%+ market share). Learn K8s.

**Q: Can K8s run on my laptop?**  
A: Yes! Docker Desktop, Rancher Desktop, Minikube, k3d all run K8s locally. Use them for labs, then deploy to cloud K8s (EKS, GKE, AKS) for production.

---

**üéâ Congrats!** You've bridged the gap from Docker Compose to Kubernetes. Now go convert your apps! üöÄ
